{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to write a simple object detection pipeline invoking YOLOX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "import motmetrics as mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many YOLOX versions based on size, depth and efficiency and we select which yolox version to use by using the `get_exp` function provided by YOLOX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./YOLOX/\")\n",
    "from YOLOX.yolox.exp.build import get_exp_by_name\n",
    "from src.detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOX_VERSION = \"yolox-s\" #alternatives: yolox-m, yolox-l, yolox-x, yolox-tiny, yolox-nano, yolov3\n",
    "yolo_exp = get_exp_by_name(YOLOX_VERSION)\n",
    "detector = Detector(yolo_exp, filter_classes=None, device=torch.device(\"cuda\"),\n",
    "                 test_conf=0.25, nms_thres=0.65, class_agnostic=True, \n",
    "                 chkpt=\"yolo_weights/yolox_s.pth\", num_classes=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/car_traffic.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, img_info = detector(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer()\n",
    "out_img = vis.add_boxes_to_img(output[0], img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"traffic_out.jpg\", out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"img/example.mp4\")\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) \n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "while True:\n",
    "    ret_val, frame = cap.read()\n",
    "    if ret_val:\n",
    "        outputs, img_info = detector(frame)\n",
    "        result_frame = vis.add_boxes_to_img(outputs[0], img_info)\n",
    "        cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"yolox\", result_frame)\n",
    "        ch = cv2.waitKey(1)\n",
    "        if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOT20-01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bhargavi\\Dropbox\\PC\\Documents\\Programming\\MOT_from_Scratch\\object_detection_test.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bhargavi/Dropbox/PC/Documents/Programming/MOT_from_Scratch/object_detection_test.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m img_info[\u001b[39m\"\u001b[39m\u001b[39mratio\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bhargavi/Dropbox/PC/Documents/Programming/MOT_from_Scratch/object_detection_test.ipynb#X53sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m j, box \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(outputs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Bhargavi/Dropbox/PC/Documents/Programming/MOT_from_Scratch/object_detection_test.ipynb#X53sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     row \u001b[39m=\u001b[39m [i, j] \u001b[39m+\u001b[39;49m box\u001b[39m.\u001b[39;49mnumpy()[:\u001b[39m4\u001b[39;49m] \u001b[39m+\u001b[39m [\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bhargavi/Dropbox/PC/Documents/Programming/MOT_from_Scratch/object_detection_test.ipynb#X53sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     df_rows\u001b[39m.\u001b[39mappend(row)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bhargavi/Dropbox/PC/Documents/Programming/MOT_from_Scratch/object_detection_test.ipynb#X53sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (4,) "
     ]
    }
   ],
   "source": [
    "test_dir = \"data/MOT20/MOT20/train/\"\n",
    "for vid_dir in os.listdir(test_dir):\n",
    "    print(vid_dir)\n",
    "    df_rows = []\n",
    "    for i, file in enumerate(os.listdir(os.path.join(test_dir, vid_dir, \"img1\"))):\n",
    "        frame = cv2.imread(os.path.join(test_dir, vid_dir, \"img1\", file))\n",
    "        outputs, img_info = detector(frame)\n",
    "        result_frame = vis.add_boxes_to_img(outputs[0], img_info)\n",
    "        #cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "        #cv2.imshow(\"yolox\", result_frame)\n",
    "        #ch = cv2.waitKey(1)\n",
    "        #if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "        #    break\n",
    "        outputs = outputs[0].cpu()\n",
    "        outputs /= img_info[\"ratio\"]\n",
    "        for j, box in enumerate(outputs):\n",
    "            row = [i, j] + box.numpy()[:4] + [1,-1,-1,-1]\n",
    "            df_rows.append(row)\n",
    "            break\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for seqname in os.listdir(test_dir):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e493a1a15d7e27fb4e49f83da841848447539036e41bf31e3db46ef82884d8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
