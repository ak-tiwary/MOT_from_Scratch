{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to write a simple object detection pipeline invoking YOLOX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "import motmetrics as mm\n",
    "import importlib\n",
    "from loguru import logger\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many YOLOX versions based on size, depth and efficiency and we select which yolox version to use by using the `get_exp` function provided by YOLOX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./YOLOX/\")\n",
    "from YOLOX.yolox.exp.build import get_exp_by_name\n",
    "import src.detector as det\n",
    "import src.tracker as track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOX_VERSION = \"yolox-s\" #alternatives: yolox-m, yolox-l, yolox-x, yolox-tiny, yolox-nano, yolov3\n",
    "yolo_exp = get_exp_by_name(YOLOX_VERSION)\n",
    "detector = det.Detector(yolo_exp, filter_classes=None, device=torch.device(\"cuda\"),\n",
    "                 test_conf=0.25, nms_thres=0.65, class_agnostic=True, \n",
    "                 chkpt=\"yolo_weights/yolox_s.pth\", num_classes=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/car_traffic.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, img_info = detector(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer()\n",
    "out_img = vis.add_boxes_to_img(output, img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"traffic_out.jpg\", out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tracker = track.Tracker(det=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(\"img/example.mp4\")\n",
    "# width = cap.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "# height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) \n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# time_elapsed = 0\n",
    "# frame_count = 0\n",
    "# cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "# while True:\n",
    "#     ret_val, frame = cap.read()\n",
    "#     frame_count += 1\n",
    "#     if ret_val and (15 <= frame_count <= 17):\n",
    "#         logger.info(f\"Here!\")\n",
    "        \n",
    "#         outputs, img_info = detector(frame)\n",
    "#         result_frame = vis.add_boxes_to_img(outputs, img_info)\n",
    "#         cv2.imshow(\"yolox\", result_frame)\n",
    "#         #if 15 <= frame_count <= 17:\n",
    "#         #cv2.imshow(\"yolox\", frame)\n",
    "        \n",
    "#         #if frame_count == 1:\n",
    "#         #    cv2.waitKey(0)\n",
    "#         cv2.waitKey(0)\n",
    "        \n",
    "#         # ch = cv2.waitKey(1)\n",
    "#         # if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "#         #     break\n",
    "    \n",
    "#     else:\n",
    "#         continue\n",
    "    \n",
    "#     if frame_count >= 17:\n",
    "#         break\n",
    "    \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"img/MOT20-02-raw.webm\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH )) \n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "time_elapsed = 0\n",
    "frame_count = 0\n",
    "cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "detector = det.Detector(yolo_exp, filter_classes=[0], device=torch.device(\"cuda\"),\n",
    "                 test_conf=0.25, nms_thres=0.65, class_agnostic=True, \n",
    "                 chkpt=\"yolo_weights/yolox_s.pth\", num_classes=80)\n",
    "my_tracker = track.Tracker(det=detector)\n",
    "\n",
    "\n",
    "LOWER_FRAME=16\n",
    "HIGHER_FRAME=20\n",
    "try:\n",
    "    out = cv2.VideoWriter('img/MOT_test.avi',cv2.VideoWriter_fourcc(*'MJPG'), 60, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret_val, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if ret_val:\n",
    "            #if (LOWER_FRAME <= frame_count <= HIGHER_FRAME):\n",
    "                result_frame, curr_time = my_tracker.step(frame)\n",
    "                time_elapsed += curr_time\n",
    "                out.write(result_frame)\n",
    "                cv2.imshow(\"yolox\", result_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            #if frame_count >= HIGHER_FRAME: break\n",
    "        \n",
    "        else:\n",
    "            break \n",
    "except Exception as e:\n",
    "    logger.error(traceback.format_exc())\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"data/MOT20/MOT20/train/\"\n",
    "for vid_dir in os.listdir(test_dir):\n",
    "    print(vid_dir)\n",
    "    df_rows = []\n",
    "    for i, file in enumerate(os.listdir(os.path.join(test_dir, vid_dir, \"img1\"))):\n",
    "        frame = cv2.imread(os.path.join(test_dir, vid_dir, \"img1\", file))\n",
    "        outputs, img_info = detector(frame)\n",
    "        result_frame = vis.add_boxes_to_img(outputs[0], img_info)\n",
    "        #cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "        #cv2.imshow(\"yolox\", result_frame)\n",
    "        #ch = cv2.waitKey(1)\n",
    "        #if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "        #    break\n",
    "        outputs = outputs[0].cpu()\n",
    "        outputs /= img_info[\"ratio\"]\n",
    "        for j, box in enumerate(outputs):\n",
    "            row = [i, j] + box.numpy()[:4] + [1,-1,-1,-1]\n",
    "            df_rows.append(row)\n",
    "            break\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqname in os.listdir(test_dir):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1899c2cfeb0a97bb7f796d16f358d950e5c18ee1c44c1d930b588549039f22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
